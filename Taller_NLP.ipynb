{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller-NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergiocastro85/trabajosPython/blob/main/Taller_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMD6waZ2AmPf"
      },
      "source": [
        "# **Taller: introducción al procesamiento del lenguaje natural**\n",
        "\n",
        "Por favor lea con atención **TODAS** las instrucciones para que el taller se le califique de acuerdo a los requerimientos.\n",
        "\n",
        "**Objetivo:** construir un modelo TF-IDF con base en un corpus de documentos  y calcular la similitud coseno entre estos documentos que conforman el corpus.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Primera parte: responder las siguientes preguntas\n",
        "1. Descargue y descomprima el corpus (ejecute la celda indicada)\n",
        "2. ¿Cuántos documentos tiene el corpus?\n",
        "3. Explore dos o tres documentos al azar e indique qué tipo de documentos son los del corpus: cuentos, sinópsis de películas, chistes, novelas, libros, discursos, etc.\n",
        "4. ¿Cuál es el tipo de archivo de los documentos del corpus?\n",
        "\n",
        "---\n",
        "\n",
        "# Segunda parte: flujo de trabajo y responder preguntas planteadas\n",
        "\n",
        "Realice lo siguiente con **cada documento** del corpus:\n",
        "\n",
        "1. Obtener el texto en \"bruto\" (`raw`) de cada documento.\n",
        "2. Convierta todo el texto en bruto en minúsculas. `raw = raw.lower()`.\n",
        "3. Obtener del texto en bruto del numeral anterior (`raw`), una lista de tokens de palabras **usando** `nltk.tokenize.word_tokenize` **pasando como parámetro el lenguaje usado en el contenido de los documentos del corpus**.\n",
        "4. Obtenga una **nueva** lista de tokens de palabras **usando** `nltk.tokenize.RegexTokenizer` y empleando la siguiente expresión regular como parámetro del tokenizador: `'\\w+'`.\n",
        "    1. ¿Qué diferencias encuentra con la lista de tokens del numeral anterior? Sugerencia: imprima ambas listas, mida la longitud y compare.\n",
        "5. Tomando la lista de tokens del punto anterior, crear una **nueva** lista de tokens filtrando (eliminando) las *stop words*.\n",
        "6. Tomando la lista de tokens del punto anterior, crear una **nueva** lista de tokens filtrando (eliminando) de la lista, los tokens que sean de menos de tres caractéres de longitud.\n",
        "7. Tomando la lista de tokens del punto anterior, crear una **nueva** lista de tokens eliminando acentos en las palabras.\n",
        "8. Tomando la lista de tokens del punto anterior, crear una **nueva** lista de tokens obtienendo el *stem* de cada token.\n",
        "9. Agregue como elemento de **una nueva lista**, la lista del punto anterior. Cada lista producida en el numeral ocho debe ser agregada como elemento de esta nueva lista lista. Define esta lista vacia al principio del código y vaya agregando cada una de las listas que va obteniendo en el numeral anterior.\n",
        "10. Crear una **nueva lista** que corresponde al corpus que se le debe entregar a la clase `TfidfVectorizer` de la librería `sklearn`. **Nota: Ver diapositivas de clase**.\n",
        "11. Crear el modelo TF-IDF.\n",
        "    1. ¿Cuántos términos conforman el vocabulario del corpus?\n",
        "12. Medir la similitud entre los documentos usando la medida de similitud coseno.\n",
        "    1. Muestre la matriz de coeficientes de similitud entre los documentos del corpus.\n",
        "    2. ¿Cuáles son los documentos que más se parecen entre sí? ¿Podría verfificar si es cierto? Justifique.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twxefmttKP7N"
      },
      "source": [
        "# **Pseudocódigo de guía para la fase de preprocesamiento del texto**\n",
        "\n",
        "El siguiente pseudocódigo tiene como propósito ilustrar toda la etapa de preprocesamiento de texto indicada en los numerales anteriores. Al finalizar debe obtener el conjunto $ D $ (una lista de Python) que corresponde a una lista de tokens en el formato que se necesita para usar `TfidfVectorizer()` de la librería `Sklearn`. Una vez obtenido $ D $, use el mismo código de Python que encuentra en las diapositivas para construir el modelo TF-IDF.\n",
        "\n",
        "Las listas $ T3, T4, T5, T6, T7 $ y $ T8 $ en el siguiente pseudocódigo corresponden a las listas que se piden en los mismos numerales de la sección anterior.\n",
        "\n",
        "**Convenciones usadas en este pseudocódigo**\n",
        "\n",
        "Símbolo           | Significado\n",
        "------------------|------------------\n",
        "$ \\leftarrow $    | Operador de asignación.\n",
        "$ \\emptyset $     | Conjunto vacío, inicialización de listas, arreglos, etc.\n",
        "$ \\triangleright $| Se usa para indicar comentarios .\n",
        "$ \\cup $          | Operador de unión. P. Ej. agregar elementos a una lista, arreglo.\n",
        "$ \\in $           | Pertenece a.\n",
        "$ \\notin $        | No pertenece a.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$ imports\\ \\text{...} $\n",
        "\n",
        "$ \\text {Sea}\\ S\\ \\text{un conjunto de stop words} $\n",
        "\n",
        "$ \\text {Sea}\\ A\\ \\text{el conjunto de archivos que conforman el corpus} $\n",
        "\n",
        "$ T  \\leftarrow \\emptyset \\triangleright \\text{Conjunto para construir el corpus de tokens que indica el numeral 9} $\n",
        "\n",
        "$ \\textbf{for all}\\ archivo \\in A\\ \\textbf{do} $\n",
        "\n",
        ">$  a \\leftarrow open(archivo) $\n",
        "\n",
        ">$ raw \\leftarrow a.read() $\n",
        "\n",
        ">$ raw \\leftarrow raw.lower() $\n",
        "\n",
        ">$ a.close() $\n",
        "\n",
        ">$ T3 \\leftarrow word\\_tokenize(raw, language) \\triangleright \\text{Conjunto tokens en bruto} $\n",
        "\n",
        ">$ rt \\leftarrow RegexpTokenizer(\\text{\"\\\\w+\"})$\n",
        "\n",
        ">$ T4 \\leftarrow rt.tokenize(raw) $\n",
        "\n",
        ">$ T5 \\leftarrow \\emptyset \\triangleright \\text{Conjunto tokens sin stop words}$\n",
        "\n",
        ">$ \\textbf{for all}\\ t \\in T4\\ \\textbf{do} $\n",
        "\n",
        ">> $ \\textbf{if}\\ t \\notin S\\ \\textbf{then}$\n",
        "\n",
        ">>> $ T5 \\leftarrow T5 \\cup \\{t\\} $\n",
        "\n",
        ">> $ \\textbf{end if} $\n",
        "\n",
        "> $ \\textbf{end for} $\n",
        "\n",
        ">$ T6 \\leftarrow \\emptyset \\triangleright \\text{Conjunto tokens longitud > 3}$\n",
        "\n",
        ">$ \\textbf{for all}\\ t \\in T5\\ \\textbf{do} $\n",
        "\n",
        ">> $ \\textbf{if}\\ length(t) > 3\\ \\textbf{then}$\n",
        "\n",
        ">>> $ T6 \\leftarrow T6 \\cup \\{t\\} $\n",
        "\n",
        ">> $ \\textbf{end if} $\n",
        "\n",
        "> $ \\textbf{end for} $\n",
        "\n",
        ">$ T7 \\leftarrow \\emptyset \\triangleright \\text{Conjunto tokens normalizado}$\n",
        "\n",
        ">$ \\textbf{for all}\\ t \\in T6\\ \\textbf{do} $\n",
        "\n",
        ">> $ t \\leftarrow unidecode(t) $\n",
        "\n",
        ">>$ T7 \\leftarrow T7 \\cup \\{t\\} $\n",
        "\n",
        "> $ \\textbf{end for} $\n",
        "\n",
        ">$ T8 \\leftarrow \\emptyset \\triangleright \\text{Conjunto tokens stems}$\n",
        "\n",
        ">$ \\textbf{for all}\\ t \\in T7\\ \\textbf{do} $\n",
        "\n",
        ">> $ t \\leftarrow stem(t) $\n",
        "\n",
        ">>$ T8 \\leftarrow T8 \\cup \\{t\\} $\n",
        "\n",
        "> $ \\textbf{end for} $\n",
        "\n",
        "> $ T \\leftarrow T \\cup \\{T8\\} $\n",
        "\n",
        "$ \\textbf{end for} $\n",
        "\n",
        "$ \\triangleright \\text{El siguiente código para el numeral 10} $\n",
        "\n",
        "$ D \\leftarrow \\emptyset \\triangleright \\text{Corpus de tokens para TfidfVectorizer()}$\n",
        "\n",
        "$ \\textbf{for all}\\ e \\in T\\ \\textbf{do}$\n",
        "\n",
        ">$ \\triangleright \\text{Tal cual en Python lo siguiente} $\n",
        "\n",
        ">$ t \\leftarrow \\text{'  '}.join(e) \\triangleright \\text{Va un espacio en blanco en las comillas}$\n",
        "\n",
        ">$ D \\leftarrow D \\cup \\{t\\}$\n",
        "\n",
        "$ \\textbf{end for} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycIVTwBzlkGt"
      },
      "source": [
        "# **Descarga del corpus usado en el taller**\n",
        "\n",
        "Por favor ejecute las siguientes celdas para la descarga y descompresión del corpus. Si tiene algún inconveniente en esta fase por favor haga lo siguiente:\n",
        "\n",
        "1. Clic en el menú **Entorno de ejecución**\n",
        "2. Clic en **Restablecer el estado de fábrica del entorno de ejecución** \n",
        "3. Ejecute de nuevo las celdas de código"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n"
      ],
      "metadata": {
        "id": "E294gg3AwTay"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Dj4Tt-AhzY"
      },
      "source": [
        "!wget -O CorpusTallerNLP.zip https://drive.google.com/u/0/uc?id=1y_Em0jgijsfxgqrSBdI59Fk_r7P2MeMk&export=download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFMN4PykRoD"
      },
      "source": [
        "!unzip -o -d /root CorpusTallerNLP.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoXGOZyxmmcx"
      },
      "source": [
        "# **Establecimiento de la ruta de trabajo**\n",
        "\n",
        "Ejecute la siguiente celda para establecer la ubicación de ejecución del código Python a la misma ubicación de los archivos del corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SHm497qmyQe"
      },
      "source": [
        "corpusdir = '/root/CorpusTallerNLP/'\n",
        "import os\n",
        "os.chdir(corpusdir)\n",
        "archivos_corpus = sorted(os.listdir('.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8H0Rw4mnMDP"
      },
      "source": [
        "# **Desarrollo del taller**\n",
        "\n",
        "A partir de este punto su código...(buena suerte)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZhyPHyOnLg6"
      },
      "source": [
        "# Su código aquí o en mas celdas de código\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GayoecZnimE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Taller y corpus preparado por Juan Felipe Muñoz Fernández | jfmunozf@unal.edu.co "
      ]
    }
  ]
}